<!-- -------------------------------------------------------------------- -->

<!--  README.md â€” nHDPâ€‘GNN                                               -->

<!--  Compatible with the manuscript: â€œMitigating Overâ€‘Smoothing in      -->

<!--  Graph Neural Networks via Nested Hierarchical Dirichlet Clusteringâ€-->

<!-- -------------------------------------------------------------------- -->

# nHDPâ€‘GNN

**Nestedâ€‘Hierarchical Dirichlet Clustering for Overâ€‘Smoothingâ€‘Resilient Graph Neural Networks**

> A threeâ€‘stage Graph Attention Network that fuses **Louvain communities**, a **nested Dirichletâ€‘inspired hierarchy** and a **variational latent bottleneck**.  The architecture reproduces all experiments and figures reported in the companion paper *Mitigating Overâ€‘Smoothing in Graph Neural Networks via Nested Hierarchical Dirichlet Clustering* and exceeds baseline performance on Cora, Citeseer, and PubMed.

<p align="center">
  <img src="docs/architecture.svg" width="600" alt="Block diagram of the threeâ€‘stage nHDPâ€‘GNN"/>
</p>

[![Paper](https://img.shields.io/badge/Paper-PDF-blue)](docs/oversmoothing_nhdp_gnn.pdf)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9%2B-green.svg)](https://www.python.org/)
[![PyG](https://img.shields.io/badge/PyTorch%20Geometric-2.x-orange)](https://pytorch-geometric.readthedocs.io/)

---

## ğŸ“°  Repository at a Glance

| Folder / file                     | What it contains                                                     | Related paper section |
| --------------------------------- | -------------------------------------------------------------------- | --------------------- |
| `src/main.py`                     | Endâ€‘toâ€‘end script to reproduce TablesÂ 2Â &Â 3 (Cora experiments)       | Â§Â 5.1, Â§Â 6.1          |
| `src/models.py`                   | Implementation of **EnhancedÂ VariationalÂ HierarchicalÂ GAT**          | Â§Â 4 (Model)           |
| `src/clustering.py`               | Louvain community detection + nâ€‘HDP surrogate clustering             | Â§Â 3 (Preâ€‘processing)  |
| `src/metrics.py`                  | Overâ€‘smoothing / embedding distinctness metrics                      | Â§Â 6.3                 |
| `notebooks/`                      | Jupyter notebooks that generate Fig.Â 7 (tâ€‘SNE) & Fig.Â 9 (histograms) | Figures 7â€‘10          |
| `docs/oversmoothing_nhdp_gnn.pdf` | **The manuscript (cameraâ€‘ready)**                                    | â€”                     |

> **Tip:** every figure displayed in the paper can be regenerated with a single make target: `make plots` (see `Makefile`).

---

## âœ¨  Key Contributions (mirrors the manuscript)

| Contribution                                                                                 | Code component                                   | Where it appears in the PDF |
| -------------------------------------------------------------------------------------------- | ------------------------------------------------ | --------------------------- |
| 1. **Hierarchical graph signal**: Louvainâ†’nâ€‘HDP labels concatenated to node features         | `clustering.py â€º build_hierarchy()`              | Fig.Â 3, Eq.Â (5â€“8)           |
| 2. **Threeâ€‘stage multiâ€‘head GAT** (local â–¸ community â–¸ global) with residual skipâ€‘connection | `models.py â€º EnhancedVariationalHierarchicalGAT` | Fig.Â 4, TableÂ 1             |
| 3. **Variational bottleneck** (Î¼,â€¯Ïƒ, KL penalty Î²)                                           | same module                                      | Eq.Â (12â€“14)                 |
| 4. **Auxiliary community loss** to keep embeddings discriminative                            | `losses.py`                                      | Eq.Â (15)                    |
| 5. **Overâ€‘smoothing diagnostics** (pairwise/inter/intra, variance, NMI/ARI)                  | `metrics.py`                                     | Fig.Â 8, TableÂ 4             |

---

## ğŸš€  Quick Start

### 1ï¼Clone & install

```bash
# Clone the repo
$ git clone https://github.com/<user>/nHDPâ€‘GNN.git
$ cd nHDPâ€‘GNN

# (Optional) create a virtual environment
$ python -m venv .venv
$ source .venv/bin/activate

# Install dependencies (CPU or CUDA wheel autoâ€‘detected)
$ pip install -r requirements.txt
```

### 2ï¼Reproduce a paper table (Cora example)

```bash
$ python src/main.py \
        --dataset cora \
        --depth 3 \
        --heads 4 \
        --latent-dim 32 \
        --beta 2e-5
```

The script prints accuracy, F1, AUC, and overâ€‘smoothing metrics, then pops up the loss curves, tâ€‘SNE, histograms and confusionâ€‘matrix exactly as shown in FiguresÂ 6â€“10 of the manuscript.

---

## ğŸ—ï¸  Extending the Work

* **Replace the nâ€‘HDP surrogate** with a true nested Dirichlet Process using `pyro` â€“ see wiki page *Advanced Clustering*.
* **Scale to OGB datasets**: `--dataset ogbn-arxiv` works outâ€‘ofâ€‘theâ€‘box; increase `--depth` and adjust GPU memory.
* **Synthetic graphs**: `scripts/gen_synthetic.py` generates the overâ€‘smoothing test suite used in SectionÂ 6.4.

---

## ğŸ”’  License

* **Code**: MIT â€” see [`LICENSE`](LICENSE).
* **Manuscript & figures**: Creative Commons Attribution 4.0 â€” see [`docs/LICENSE-CC-BY.txt`](docs/LICENSE-CC-BY.txt).

---

## ğŸ™  Acknowledgements

This project was supported by the Wallenberg AI, Autonomous Systems and Software Program (WASP).
